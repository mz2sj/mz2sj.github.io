---
title: 03-CV入门之模型构建
date: 2020-05-26 21:15:59
tags: [CV,CNN]
categories: [CV]
---

### CNN介绍

​	卷积神经网络（简称CNN）是一类特殊的人工神经网络，是深度学习中重要的一个分支。CNN在很多领域都表现优异，精度和速度比传统计算学习算法高很多。特别是在计算机视觉领域，CNN是解决图像分类、图像检索、物体检测和语义分割的主流模型。 

​	CNN是一种层次模型，输入的是原始的像素数据。CNN通过卷积（convolution）、池化（pooling）、非线性激活函数（non-linear activation function）和全连接层（fully connected layer）构成。 利用pytorch我们可以很方便实现。

```python
#顺序依次是卷积、激活函数、池化
cnn=nn.Sequential(
        nn.Conv2d(3,16,kernel_size=(3,3),stride=(2,2)),
        nn.ReLU(),
        nn.MaxPool2d(2),
        nn.Conv2d(16,32,kernel_size=(3,3),stride=(2,2)),
        nn.ReLU(),
        nn.MaxPool2d(2),
    )
```

​	与传统机器学习模型相比，CNN具有一种端到端（End to End）的思路。在CNN训练的过程中是直接从图像像素到最终的输出，并不涉及到具体的特征提取和构建模型的过程，也不需要人工的参与。

###  模型构建

下面写一下代码的完整流程

```python
#数据
import os,sys,glob,shutil,json
import cv2

from PIL import Image
import numpy as np

import torch
from torch.utils.data.dataset import Dataset
import torchvision.transforms as transforms


class SVHNDataset(Dataset):
  def __init__(self,img_path,img_label,transform=None):
    self.img_path=img_path
    self.img_label=img_label
    if transform is not None:
      self.transform=transform
    else:
      self.transform=None

  def __getitem__(self,index):
    img=Image.open(self.img_path[index]).convert('RGB')

    if self.transform is not None:
      img=self.transform(img)
    
    lbl=np.array(self.img_label[index],dtype=np.int)
    lbl=list(lbl)+(5-len(lbl))*[10]

    return img,torch.from_numpy(np.array(lbl[:6]))

  def __len__(self):
    return len(self.img_path)

train_path=glob.glob('./data/mchar_train/*.png')
train_path.sort()
train_json=json.load(open('./data/mchar_train.json'))
train_label=[train_json[x]['label'] for x in train_json]


data=SVHNDataset(train_path,train_label,transforms.Compose([
        transforms.Resize((64,128)),
        transforms.ColorJitter(0.2,0.2,0.2),
        transforms.RandomRotation(5),
]))

train_loader=torch.utils.data.DataLoader(
    SVHNDataset(train_path,train_label,
          transforms.Compose([
            transforms.Resize((64,128)),
            transforms.ColorJitter(0.3,0.3,0.2),
            transforms.RandomRotation(5),
            transforms.ToTensor(),
            transforms.Normalize([0.485,0.456,0.406],[0.229,0.224,0.225])
          ])),
    batch_size=10,
    shuffle=False,
    num_workers=10
)
```

```python
#模型
class SVHN_Model1(nn.Module):
  def __init__(self):
    super(SVHN_Model1,self).__init__()
    self.cnn=nn.Sequential(
        nn.Conv2d(3,16,kernel_size=(3,3),stride=(2,2)),
        nn.ReLU(),
        nn.MaxPool2d(2),
        nn.Conv2d(16,32,kernel_size=(3,3),stride=(2,2)),
        nn.ReLU(),
        nn.MaxPool2d(2),
    )
    self.fc1=nn.Linear(32*3*7,11)
    self.fc2=nn.Linear(32*3*7,11)
    self.fc3=nn.Linear(32*3*7,11)
    self.fc4=nn.Linear(32*3*7,11)
    self.fc5=nn.Linear(32*3*7,11)

  def forward(self,img):
    feat=self.cnn(img)
    feat=feat.view(feat.shape[0],-1)
    c1=self.fc1(feat)
    c2=self.fc2(feat)
    c3=self.fc3(feat)
    c4=self.fc4(feat)
    c5=self.fc5(feat)
    
    
    return c1,c2,c3,c4,c5
```

```python
#使用预训练模型
class SVHN_Model2(nn.Module):
  def __init__(self):
    super(SVHN_Model2,self).__init__()
    
    model_conv=models.resnet18(pretrained=True)
    model_conv.avgpool=nn.AdaptivedAvgPool2d(1)
    model_conv=nn.Sequential(*list(model_conv.children())[:-1])
    self.cnn=model_conv

    self.fc1=nn.Linear(512,11)
    self.fc2=nn.Linear(512,11)
    self.fc3=nn.Linear(512,11)
    self.fc3=nn.Linear(512,11)
    self.fc4=nn.Linear(512,11)
    self.fc5=nn.Linear(512,11)

  def forward(self,img):
    feat=self.cnn(img)
    feat=feat.view(feat.shape[0],-1)
    c1=self.fc1(feat)
    c2=self.fc2(feat)
    c3=self.fc3(feat)
    c4=self.fc4(feat)
    c5=self.fc5(feat)

    return c1,c2,c3,c4,c5
```



```python
#pipeline
model=SVHN_Model1()
model.cuda()
%%time
criterion=nn.CrossEntropyLoss()
optimizer=torch.optim.Adam(model.parameters(),0.005)

loss_plot,c0_plot=[],[]

for epoch in range(10):
  for data in train_loader:
    data[0]=data[0].cuda()
    data[1]=data[1].cuda()
    c0,c1,c2,c3,c4=model(data[0])
    loss=criterion(c0,data[1][:,0].long())+\
        criterion(c1,data[1][:,1].long())+\
        criterion(c2,data[1][:,2].long())+\
        criterion(c3,data[1][:,3].long())+\
        criterion(c4,data[1][:,4].long())
      
    loss/=5
    optimizer.zero_grad()
    loss.backward()
    optimizer.step()

    loss_plot.append(loss.item())
    c0_plot.append((c0.argmax(1)==data[1][:,0]).sum().item()*1.0/c0.shape[0])

  print(epoch)
```

至此就完成了，这里的pipeline并不完整，只包含了训练的代码，还未包含模型的预测，模型的训练与验证下次再说。

