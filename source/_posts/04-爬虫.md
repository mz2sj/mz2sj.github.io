---
title: 04-爬虫
date: 2020-04-27 16:57:35
tags: [腾讯新闻爬虫,ajax]
categories: [爬虫]
---

### chrome监控ajax请求

浏览器中输入腾讯新闻的网址，发现不断向下拉滚动条就可以新闻会不断出现，初步判断新出现的新闻是通过ajax加载的。打开chrome的开发者工具，进入network中的js界面，将js脚本按名称排序，继续向下拉动滚动条，可以发现新出现的请求有规律。

![JfrVbR.png](https://s1.ax1x.com/2020/04/27/JfrVbR.png)

`rcd?`这个请求随着滚动条的拖动不断增加，我们把前几条请求单独拿出来分析。

` https://pacaio.match.qq.com/irs/rcd?cid=137&token=d0f13d594edfc180f5bf6b845456f3ea&id=&ext=top&page=0&expIds=&callback=__jp1 `

` https://pacaio.match.qq.com/irs/rcd?cid=4&token=9513f1a78a663e1d25b46a826f248c3c&ext=&page=0&expIds=&callback=__jp2 `

` https://pacaio.match.qq.com/irs/rcd?cid=137&token=d0f13d594edfc180f5bf6b845456f3ea&id=&ext=top&page=1&expIds=20200427A0I0UN|20200427002954|20200402012032|20200427A0CB27|20200427A0H4VM|20200427A0GJP8|20200427002536|20200426005210|20200427A0CW43|20200427A0H11D&callback=__jp4 `

` https://pacaio.match.qq.com/irs/rcd?cid=137&token=d0f13d594edfc180f5bf6b845456f3ea&id=&ext=top&page=2&expIds=20200427A0BLNR|20200427A08JMI|20200426005565|20200427A0BBTS|20200427A088DC|20200427A05064|20200427A04L6I|20200427A066PB|20200427V05K49&callback=__jp5 `

` https://pacaio.match.qq.com/irs/rcd?cid=137&token=d0f13d594edfc180f5bf6b845456f3ea&id=&ext=top&page=3&expIds=20200427V01DY9|20200427000076|20200426A0O227|20200427A00E00|20200427A02TN7|20200426A0PR2B|20200426A0PLML|20200426A0HWYG|20200426A0Q1GM|20200426A0PGG8&callback=__jp6 `

出去开头的请求规律不规范外，可以发现请求的一些规律，第三条之后的请求：`cid=137`,`page=1 2 3...`,`callback=__jp4 5 6`,从第二条开始看的话，`page=0 1 2 3`

又综合分析一下，经过自己的尝试我们可以构造出下面的请求

```python
url='https://pacaio.match.qq.com/irs/rcd?cid=137&token=d0f13d594edfc180f5bf6b845456f3ea&id=&ext=top&page={}'.format(i)
```

只需要更改`i`就可以获取不同页面的内容，并且是直接返回json，省去解析的麻烦。

不用selenium就可以爬取新闻

下面放上自己的代码

### requests爬取腾讯新闻

```python
import time
import requests


url_fmt='https://pacaio.match.qq.com/irs/rcd?cid=137&token=d0f13d594edfc180f5bf6b845456f3ea&id=&ext=top&page={}'
title_list=[]
tags_list=[]
keywords_list=[]
vurl_list=[]
intro_list=[]
category_list=[]
source_list=[]
bimg_list=[]

for page in range(100):
    url=url_fmt.format(page)
    res=requests.get(url)
    data=res.json()['data']
    
    for new in data:
        try:
            title=new['title']
            tags=new['tags']
            keywords=new['keywords']
            vurl=new['vurl']
            intro=new['intro']
            category=new['category']
            source=new['source']
            bimg=new['bimg']
        except:
            continue
        title_list.append(title)
        tags_list.append(tags)
        keywords_list.append(keywords)
        vurl_list.append(vurl)
        intro_list.append(intro)
        category_list.append(category)
        source_list.append(source)
        bimg_list.append(bimg)
    time.sleep(2)
```

```python
import pandas as pd

news=pd.DataFrame({'title':title_list,
                   'tags':tags_list,
                   'keywords':keywords_list,
                   'vurl':vurl_list,
                   'intro':intro_list,
                   'category':category_list,
                   'source':source_list,
                   'bimg':bimg_list})
news.to_csv('news.csv')
```

![Jfx7gf.png](https://s1.ax1x.com/2020/04/27/Jfx7gf.png)

大功告成！！！

### selenium模拟拖动滚动条

可以让selenium模拟拖动滚动条使新闻更新，在这里发现展示的新闻数量是有限的，拖动到一定程度将不能再拖动。

```python
import time
from  selenium import webdriver
from lxml import etree


#模拟打开界面
driver=webdriver.Chrome(r'C:\Users\MZ\Downloads\chromedriver_win32\chromedriver.exe')
driver.get('https://news.qq.com/')
driver.maximize_window()
time.sleep(3)
current_window_1=driver.current_window_handle
print(current_window_1)
```

```python
#无法拖动时退出拖动，使用chrome自带copy xpath 构造解析式
number_before=0

for i in range(50):
    driver.execute_script("window.scrollTo(0,document.body.scrollHeight-100)")
    html=driver.page_source
    tree=etree.HTML(html)
    number_after=len(tree.xpath('/html/body/div/div[4]/div[2]/div/div/ul[2]/li'))-1
    if number_before==number_after:
        break
    time.sleep(1)
    number_before=number_after
html=driver.page_source
print(number_after)
```

```python
news_number=len(tree.xpath('/html/body/div/div[4]/div[2]/div/div/ul[2]/li'))-1

title_fmt='/html/body/div/div[4]/div[2]/div/div/ul[2]/li[{}]/a/img/@alt'
img_fmt='/html/body/div/div[4]/div[2]/div/div/ul[2]/li[{}]/a/img/@src'
news_src='/html/body/div/div[4]/div[2]/div/div/ul[2]/li[{}]/a/@href'

title_list=[]
img_list=[]
src_list=[]

for number in range(news_number):
    try:
        title=tree.xpath(title_fmt.format(number))[0]
        img=tree.xpath(img_fmt.format(number))[0]
        src=tree.xpath(news_src.format(number))[0]
    except:
        continue
    
    title_list.append(title)
    img_list.append(img)
    src_list.append(src) 
```

```python
news=pd.DataFrame({'title':title_list,'url':src_list,'img':img_list})
news.to_csv('news.csv')
news.head(10)
```

![JhQp79.png](https://s1.ax1x.com/2020/04/27/JhQp79.png)