---
title: 01-爬虫入门
date: 2020-04-21 18:10:41
tags: [爬虫]
categories: [爬虫]
---

### HTTP请求

对于http请求，记录一下常用的几种：

1.  GET：向指定的资源发出“显示”请求。GET方法应该只用于读取数据 ，查询字符串（名称/值对）是在 GET 请求的 URL 中发送的 。
2.  POST：向指定资源提交数据，请求服务器进行处理（例如提交表单或者上传文件）。数据被包含在请求文本中。这个请求可能会创建新的资源或修改现有资源，或二者皆有。  查询字符串（名称/值对）是在 POST 请求的 HTTP 消息主体中发送的 
3.  PUT：向指定资源位置上传输最新内容。 
4.  DELETE：请求服务器删除Request-URL所标识的资源。

### requests.get

实现基本的requests应用，爬取python之禅

```python
import requests
url='https://www.python.org/dev/peps/pep-0020/'
res=request.get(url)
text=res.text
```

此时返回的text是html原生文本，想要获取对应内容就需要进行匹配了。

```python
with open('zon_of_python.txt','w') as f:
    f.write(text[text.find('<pre')+28:text.find('</pre>')-1])
print(text[text.find('<pre')+28:text.find('</pre')-1])

Beautiful is better than ugly.
Explicit is better than implicit.
Simple is better than complex.
Complex is better than complicated.
Flat is better than nested.
Sparse is better than dense.
Readability counts.
Special cases aren't special enough to break the rules.
Although practicality beats purity.
Errors should never pass silently.
Unless explicitly silenced.
In the face of ambiguity, refuse the temptation to guess.
There should be one-- and preferably only one --obvious way to do it.
Although that way may not be obvious at first unless you're Dutch.
Now is better than never.
Although never is often better than *right* now.
If the implementation is hard to explain, it's a bad idea.
If the implementation is easy to explain, it may be a good idea.
Namespaces are one honking great idea -- let's do more of those!
```

python自带的urllib也能实现上述功能

```python
import urllib
url = 'https://www.python.org/dev/peps/pep-0020/'
res=urllib.request.urlopen(url).read().decode('utf-8')
print(res[res.find('<pre')+28:res.find('</pre')-1])
```

urllib明显要繁琐些。

### request.post

request.get只是从网站上爬取已有数据，当我们需要和网站进行数据交互时，就要用到post方法。

```python
import requests
def translate(word):
    url="http://fy.iciba.com/ajax.php?a=fy"
    data={
        'f':'auto',
        't':'atuo',
        'w':word,
    }
    
    headers={'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/81.0.4044.113 Safari/537.36'}
    
    response=requests.post(url,data=data,headers=headers)
    json_data=response.json()
    return json_data

def run(word):
    result=tranlate(word)['content']['out']
    print(result)
    return result

def main():
    with open('zon_of_python.txt') as f:
        zh=[run(word) for word in f]
        
    with open('zon_of_python_zh-CN.txt','w') as g:
        for i in zh:
            g.write(i+'\n')

if __name__=='__main__':
    main()
```

data内容和格式的确定需要从chrome的检查工具network中的Headers获取。

### 爬取豆瓣电影top250

1.  首先要找到我们要爬取的东西在网页的位置，借助检查工具，可以找到对用位置的代码：

![JGGbKs.png](https://s1.ax1x.com/2020/04/21/JGGbKs.png)

借助匹配规则就可以拿到想要的东西（ps：还不会匹配呀，应该是要根据html元素的层级关系来匹配）。借助检查工具中的**Copy Xpath**功能，可以找到电影名和图片超链接的位置。

![JGt7xe.png](https://s1.ax1x.com/2020/04/21/JGt7xe.png) 

获取电影名和图片超链接的Xpath公式为

```python
//*[@id="content"]/div/div[1]/ol/li[23]/div/div[1]/a/img/@alt
//*[@id="content"]/div/div[1]/ol/li[23]/div/div[1]/a/img/@src
```

其中23是电影对应的当前页次序，范围是1-25，刚开始以为是电影的排名还出错了。

2.  电影分布在好几个页面，所以还要找出翻页的规律，借助检查工具点击页码，找到对应位置的代码：

   ![JGJtJS.png](https://s1.ax1x.com/2020/04/21/JGJtJS.png)

可以发现其中url对应的数字规律，0 25 50...

```python
from lxml import etree
import time


dic={}
headers={
      'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/81.0.4044.113 Safari/537.36'
    }


def get_name_imgpath(text):
    html = etree.HTML(text)
    for i in range(1,26):
        name = html.xpath('//*[@id="content"]/div/div[1]/ol/li[{}]/div/div[1]/a/img/@alt'.format(i))
        img_path=html.xpath('//*[@id="content"]/div/div[1]/ol/li[{}]/div/div[1]/a/img/@src'.format(i))
        print(name[0],img_path[0])
        dic.update({name[0]:img_path[0]})

print('crawl start')

for page in range(0,226,25):
    text=requests.get('https://movie.douban.com/top250?start={}&filter='.format(page),headers=headers).text
    get_name_imgpath(text)
    time.sleep(1)
    
print('crawl finish')
print(dic)
```

程序运行成功

![JGfZ24.png](https://s1.ax1x.com/2020/04/21/JGfZ24.png)

收工！！！

